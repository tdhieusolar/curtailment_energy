# processors/task_processor.py
"""
Xá»­ lÃ½ tÃ¡c vá»¥ vá»›i tá»‘i Æ°u cho Ã­t tasks - PhiÃªn báº£n 0.5.3
"""

import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

from core.driver_pool import DynamicDriverPool
from core.task_queue import SmartTaskQueue, InverterTask
from core.controller import InverterController
from core.logger import InverterControlLogger

class TaskProcessor:
    """Xá»­ lÃ½ tÃ¡c vá»¥ vá»›i tá»‘i Æ°u cho Ã­t tasks"""
    
    def __init__(self, config, system_urls):
        self.config = config
        self.system_urls = system_urls
        self.logger = InverterControlLogger(config)
        self.task_queue = SmartTaskQueue(config)
        self.driver_pool = DynamicDriverPool(config)
        self.active_tasks = 0
        self.active_lock = threading.Lock()
    
    def prepare_tasks(self, control_requests):
        """Chuáº©n bá»‹ tasks vÃ  tÃ­nh toÃ¡n sá»‘ lÆ°á»£ng"""
        tasks = []
        total_inverters = 0
        
        for zone_name, stations in self.system_urls.items():
            for station_name, inverters in stations.items():
                if station_name in control_requests:
                    request = control_requests[station_name]
                    required_action = request["action"]
                    required_count = request["count"]
                    
                    sorted_invs = sorted(inverters.items())
                    count_added = 0
                    
                    for inv_name, inv_info in sorted_invs:
                        if count_added >= required_count:
                            break
                            
                        full_inv_name = f"{station_name}-{inv_name}"
                        target_url = inv_info["url"]
                        inv_status = inv_info.get("status", "OK").upper()
                        
                        task = InverterTask(full_inv_name, target_url, required_action, inv_status)
                        tasks.append(task)
                        count_added += 1
                        total_inverters += 1
        
        return tasks, total_inverters
    
    def process_single_inverter(self, task):
        """Xá»­ lÃ½ má»™t inverter"""
        with self.active_lock:
            self.active_tasks += 1
            current_active = self.active_tasks
        
        self.logger.log_debug(f"ğŸ¯ Báº¯t Ä‘áº§u xá»­ lÃ½ {task.required_action} (active: {current_active})", task.full_inv_name)
        
        try:
            # Láº¥y driver vá»›i timeout
            driver = self.driver_pool.get_driver(timeout=25)
            if not driver:
                return task, "RETRY", "KhÃ´ng láº¥y Ä‘Æ°á»£c driver tá»« pool"
            
            # Xá»­ lÃ½ vá»›i controller
            controller = InverterController(driver, self.config)
            login_success = controller.fast_login(task.target_url)
            
            if not login_success:
                self.driver_pool.return_driver(driver)
                return task, "RETRY", "ÄÄƒng nháº­p tháº¥t báº¡i"
            
            success, message = controller.perform_grid_action(task.required_action)
            self.driver_pool.return_driver(driver)
            
            if success:
                status = "SUCCESS"
                self.logger.log_success(message, task.full_inv_name)
            else:
                if "Bá» QUA" in message:
                    status = "SUCCESS"
                    self.logger.log_info(message, task.full_inv_name)
                else:
                    status = "RETRY"
                    self.logger.log_warning(message, task.full_inv_name)
            
            return task, status, message
            
        except Exception as e:
            error_msg = f"Lá»—i xá»­ lÃ½: {str(e)}"
            self.logger.log_error(error_msg, task.full_inv_name)
            return task, "RETRY", error_msg
        finally:
            with self.active_lock:
                self.active_tasks -= 1
    
    def run_parallel_optimized(self, control_requests):
        """Cháº¡y song song vá»›i tá»‘i Æ°u cho Ã­t tasks"""
        start_time = datetime.now()
        
        # Chuáº©n bá»‹ tasks
        tasks, total_inverters = self.prepare_tasks(control_requests)
        total_tasks = len(tasks)
        
        self.logger.log_info(f"ğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ {total_tasks} tasks - PhiÃªn báº£n 0.5.3 (Optimized Pool)")
        
        if total_tasks == 0:
            self.logger.log_warning("âš ï¸ KhÃ´ng cÃ³ tÃ¡c vá»¥ nÃ o Ä‘á»ƒ xá»­ lÃ½!")
            return []
        
        # Khá»Ÿi táº¡o driver pool vá»›i sá»‘ lÆ°á»£ng tá»‘i Æ°u
        self.logger.log_info("ğŸ”„ Äang khá»Ÿi táº¡o driver pool...")
        if not self.driver_pool.initialize_pool(total_tasks):
            self.logger.log_error("âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o driver pool!")
            return []
        
        pool_info = self.driver_pool.get_pool_info()
        self.logger.log_info(f"ğŸ¯ Driver pool: {pool_info['pool_size']} drivers (Available: {pool_info['available']})")
        
        # ThÃªm tasks vÃ o queue
        self.task_queue.add_tasks(tasks)
        
        # Xá»­ lÃ½ vá»›i strategy phÃ¹ há»£p theo sá»‘ lÆ°á»£ng tasks
        if total_tasks == 1:
            # Tá»I Æ¯U: Chá»‰ 1 task â†’ xá»­ lÃ½ tuáº§n tá»±
            completed_count = self._process_single_task()
        elif total_tasks <= 3:
            # Tá»I Æ¯U: Ãt tasks â†’ xá»­ lÃ½ tuáº§n tá»± hoáº·c song song Ä‘Æ¡n giáº£n
            completed_count = self._process_few_tasks(total_tasks)
        else:
            # Nhiá»u tasks â†’ xá»­ lÃ½ song song vá»›i batch
            completed_count = self._process_many_tasks(total_tasks)
        
        # Káº¿t quáº£
        final_results = self._get_final_results()
        self._analyze_results(final_results, start_time, total_tasks)
        
        # Cleanup
        self.driver_pool.cleanup()
        return final_results
    
    def _process_single_task(self):
        """Xá»­ lÃ½ khi chá»‰ cÃ³ 1 task - Tá»‘i Æ°u tuáº§n tá»±"""
        self.logger.log_info("ğŸ”¸ Cháº¿ Ä‘á»™ tá»‘i Æ°u: 1 task â†’ xá»­ lÃ½ tuáº§n tá»±")
        
        batch_tasks = self.task_queue.get_next_batch(1)
        if not batch_tasks:
            return 0
        
        task = batch_tasks[0]
        try:
            processed_task, status, message = self.process_single_inverter(task)
            
            if status in ["SUCCESS", "SKIPPED"]:
                self.task_queue.mark_completed(processed_task, status, message)
                return 1
            elif status == "RETRY":
                if self.task_queue.add_to_retry_queue(processed_task, message):
                    self.logger.log_warning(f"â³ Task {task.full_inv_name} chuyá»ƒn sang retry queue")
                else:
                    self.task_queue.mark_completed(processed_task, "FAILED", message)
            else:
                self.task_queue.mark_completed(processed_task, status, message)
                
        except Exception as e:
            self.logger.log_error(f"Lá»—i xá»­ lÃ½ task: {e}", task.full_inv_name)
            if self.task_queue.add_to_retry_queue(task, str(e)):
                self.logger.log_warning(f"â³ Task {task.full_inv_name} chuyá»ƒn sang retry queue do lá»—i")
        
        return 0
    
    def _process_few_tasks(self, total_tasks):
        """Xá»­ lÃ½ khi cÃ³ Ã­t tasks (2-3 tasks)"""
        self.logger.log_info(f"ğŸ”¸ Cháº¿ Ä‘á»™ tá»‘i Æ°u: {total_tasks} tasks â†’ xá»­ lÃ½ Ä‘Æ¡n giáº£n")
        
        completed_count = 0
        batch_tasks = self.task_queue.get_next_batch(total_tasks)
        
        if not batch_tasks:
            return 0
        
        # Sá»­ dá»¥ng ThreadPoolExecutor vá»›i sá»‘ workers báº±ng sá»‘ tasks
        with ThreadPoolExecutor(max_workers=len(batch_tasks)) as executor:
            future_to_task = {
                executor.submit(self.process_single_inverter, task): task 
                for task in batch_tasks
            }
            
            for future in as_completed(future_to_task):
                task = future_to_task[future]
                try:
                    processed_task, status, message = future.result(timeout=30)
                    
                    if status in ["SUCCESS", "SKIPPED"]:
                        self.task_queue.mark_completed(processed_task, status, message)
                        completed_count += 1
                    elif status == "RETRY":
                        if self.task_queue.add_to_retry_queue(processed_task, message):
                            self.logger.log_warning(f"â³ Task {task.full_inv_name} chuyá»ƒn sang retry queue")
                        else:
                            completed_count += 0  # KhÃ´ng tÄƒng completed_count
                    else:
                        self.task_queue.mark_completed(processed_task, status, message)
                        completed_count += 0  # KhÃ´ng tÄƒng completed_count
                        
                except Exception as e:
                    self.logger.log_error(f"Lá»—i future: {e}", task.full_inv_name)
                    if self.task_queue.add_to_retry_queue(task, str(e)):
                        self.logger.log_warning(f"â³ Task {task.full_inv_name} chuyá»ƒn sang retry queue do timeout")
        
        return completed_count
    
    def _process_many_tasks(self, total_tasks):
        """Xá»­ lÃ½ khi cÃ³ nhiá»u tasks (>3 tasks)"""
        self.logger.log_info(f"ğŸ”¸ Cháº¿ Ä‘á»™ tiÃªu chuáº©n: {total_tasks} tasks â†’ xá»­ lÃ½ song song")
        
        completed_count = 0
        batch_number = 0
        
        while self.task_queue.has_pending_tasks():
            batch_number += 1
            batch_stats = self._process_batch_with_limits(batch_number)
            completed_count += batch_stats["completed"]
            
            # Progress reporting
            queue_stats = self.task_queue.get_stats()
            progress_percent = (completed_count / total_tasks) * 100
            
            self.logger.log_info(
                f"ğŸ“¦ Batch {batch_number}: {batch_stats['completed']} hoÃ n thÃ nh, "
                f"{batch_stats['retried']} retry, {batch_stats['failed']} tháº¥t báº¡i"
            )
            self.logger.log_info(f"ğŸ“ˆ Tiáº¿n trÃ¬nh: {completed_count}/{total_tasks} ({progress_percent:.1f}%)")
            
            # Early termination for small retry queue
            if queue_stats["primary_queue"] == 0 and queue_stats["retry_queue"] < 2:
                self.logger.log_info("â¹ï¸ Chá»‰ cÃ²n Ã­t tasks retry, káº¿t thÃºc sá»›m")
                break
        
        # Final retry
        final_retry_stats = self._process_final_retry()
        completed_count += final_retry_stats["completed"]
        
        return completed_count
    
    def _process_batch_with_limits(self, batch_number):
        """Xá»­ lÃ½ batch vá»›i giá»›i háº¡n Ä‘á»“ng thá»i"""
        batch_stats = {"completed": 0, "retried": 0, "failed": 0}
        
        # Láº¥y batch tasks (giá»›i háº¡n theo sá»‘ driver available)
        pool_info = self.driver_pool.get_pool_info()
        max_concurrent = min(
            self.config["performance"]["max_workers"],
            pool_info["available"] + 2  # +2 Ä‘á»ƒ linh hoáº¡t
        )
        
        batch_tasks = self.task_queue.get_next_batch(max_concurrent)
        
        if not batch_tasks:
            return batch_stats
        
        self.logger.log_debug(f"ğŸ”„ Batch {batch_number}: {len(batch_tasks)} tasks, {max_concurrent} concurrent")
        
        # Xá»­ lÃ½ vá»›i ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=len(batch_tasks)) as executor:
            future_to_task = {
                executor.submit(self.process_single_inverter, task): task 
                for task in batch_tasks
            }
            
            for future in as_completed(future_to_task):
                task = future_to_task[future]
                try:
                    processed_task, status, message = future.result(timeout=30)
                    
                    if status in ["SUCCESS", "SKIPPED"]:
                        self.task_queue.mark_completed(processed_task, status, message)
                        batch_stats["completed"] += 1
                    elif status == "RETRY":
                        if self.task_queue.add_to_retry_queue(processed_task, message):
                            batch_stats["retried"] += 1
                        else:
                            batch_stats["failed"] += 1
                    else:
                        self.task_queue.mark_completed(processed_task, status, message)
                        batch_stats["failed"] += 1
                        
                except Exception as e:
                    self.logger.log_error(f"Lá»—i future: {e}", task.full_inv_name)
                    if self.task_queue.add_to_retry_queue(task, str(e)):
                        batch_stats["retried"] += 1
                    else:
                        batch_stats["failed"] += 1
        
        return batch_stats
    
    def _process_final_retry(self):
        """Xá»­ lÃ½ retry cuá»‘i cÃ¹ng"""
        queue_stats = self.task_queue.get_stats()
        if queue_stats["retry_queue"] == 0:
            return {"completed": 0, "retried": 0, "failed": 0}
        
        self.logger.log_info(f"ğŸ”„ Xá»­ lÃ½ {queue_stats['retry_queue']} tasks retry cuá»‘i cÃ¹ng")
        
        final_stats = {"completed": 0, "retried": 0, "failed": 0}
        
        # Tá»I Æ¯U: Cho retry cuá»‘i, sá»­ dá»¥ng tuáº§n tá»± Ä‘á»ƒ Ä‘áº£m báº£o á»•n Ä‘á»‹nh
        batch_tasks = self.task_queue.get_next_batch(queue_stats["retry_queue"])
        
        for task in batch_tasks:
            try:
                processed_task, status, message = self.process_single_inverter(task)
                
                if status in ["SUCCESS", "SKIPPED"]:
                    self.task_queue.mark_completed(processed_task, status, message)
                    final_stats["completed"] += 1
                else:
                    self.task_queue.mark_completed(processed_task, "FAILED", f"Final retry failed: {message}")
                    final_stats["failed"] += 1
                    
            except Exception as e:
                self.logger.log_error(f"Final retry error: {e}", task.full_inv_name)
                self.task_queue.mark_completed(task, "FAILED", "Final retry timeout")
                final_stats["failed"] += 1
        
        return final_stats
    
    def _get_final_results(self):
        """Láº¥y káº¿t quáº£ cuá»‘i cÃ¹ng"""
        results = []
        
        for task in self.task_queue.completed_tasks:
            results.append((task.full_inv_name, task.completion_status, task.completion_message))
        
        for task in self.task_queue.failed_tasks:
            results.append((task.full_inv_name, "FAILED", f"VÆ°á»£t quÃ¡ sá»‘ láº§n retry: {task.last_error}"))
        
        return results
    
    def _analyze_results(self, results, start_time, total_tasks):
        """PhÃ¢n tÃ­ch vÃ  bÃ¡o cÃ¡o káº¿t quáº£"""
        end_time = datetime.now()
        duration = end_time - start_time
        
        # Thá»‘ng kÃª
        stats = {"SUCCESS": 0, "FAILED": 0, "SKIPPED": 0}
        for _, status, _ in results:
            stats[status] = stats.get(status, 0) + 1
        
        queue_stats = self.task_queue.get_stats()
        
        # In bÃ¡o cÃ¡o
        self.logger.log_info("=" * 60)
        self.logger.log_info(f"ğŸ¯ BÃO CÃO Tá»”NG Káº¾T - PHIÃŠN Báº¢N 0.5.3 (OPTIMIZED POOL)")
        self.logger.log_info("=" * 60)
        self.logger.log_info(f"ğŸ“¦ Tá»•ng sá»‘ tÃ¡c vá»¥: {total_tasks}")
        self.logger.log_info(f"ğŸ¯ Sá»‘ drivers sá»­ dá»¥ng: {self.driver_pool.get_pool_info()['pool_size']}")
        self.logger.log_info(f"âœ… ThÃ nh cÃ´ng: {stats['SUCCESS']}")
        self.logger.log_info(f"âŒ Tháº¥t báº¡i: {stats['FAILED']}")
        self.logger.log_info(f"â­ï¸ Bá» qua: {stats['SKIPPED']}")
        self.logger.log_info(f"ğŸ”„ Tá»•ng sá»‘ láº§n retry: {queue_stats['total_retries']}")
        
        if total_tasks > 0:
            success_rate = (stats['SUCCESS'] / total_tasks) * 100
            self.logger.log_info(f"ğŸ“Š Tá»· lá»‡ thÃ nh cÃ´ng: {success_rate:.1f}%")
        
        total_seconds = duration.total_seconds()
        if total_tasks > 0:
            avg_time = total_seconds / total_tasks
            self.logger.log_info(f"â±ï¸ Thá»i gian trung bÃ¬nh/task: {avg_time:.2f}s")
        
        self.logger.log_info(f"ğŸ•’ Tá»•ng thá»i gian thá»±c hiá»‡n: {duration}")
        
        # In lá»—i chi tiáº¿t
        errors = [(name, msg) for name, status, msg in results if status == "FAILED"]
        if errors:
            self.logger.log_info("ğŸ” CHI TIáº¾T Lá»–I:")
            for name, msg in errors:
                self.logger.log_error(msg, name)